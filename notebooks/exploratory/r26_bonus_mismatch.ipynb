{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "import plotly.io as pio\n",
    "import pandas as pd # type: ignore\n",
    "import random\n",
    "pio.renderers.default = \"png\"\n",
    "sys.path.append('../..')\n",
    "import xarray as xr # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the voting data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nqg_model.experiment import full_historical_data_run_plus_counterfactual\n",
    "from nqg_model.load_data import retrieve_id_maps, retrieve_vote_data\n",
    "\n",
    "## Simulation Originated Data\n",
    "round_no = 26\n",
    "folder_path = f'../../data/r{round_no}/'\n",
    "\n",
    "maps = retrieve_id_maps(folder_path)\n",
    "\n",
    "sim_backtest_df = full_historical_data_run_plus_counterfactual(folder_path=folder_path, round_no=round_no)\n",
    "sim_df = pd.concat([sim_backtest_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# sim_df.to_pickle(f\"../data/r{round_no}/sim_results/results_{datetime.now()}.pkl.zip\")\n",
    "\n",
    "## Empirical Data\n",
    "df = pd.read_csv(f'../../data/r{round_no}/votes.csv')\n",
    "df['user'] = df['user'].astype(str).map(lambda x: maps.UserID2Wallet.get(x, f'unknown-{x}'))\n",
    "df['project'] = df['project'].astype(str).map(lambda x: maps.SubmissionID2Label.get(x, f'unknown-{x}'))\n",
    "df.rename(columns={'user': 'user_ref', 'project': 'submission', 'vote_type': 'vote_type'}, inplace=True)\n",
    "\n",
    "# fixing seed for reproducibility\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_str = \"GAD27O\"\n",
    "\n",
    "\n",
    "# filtered_df = df[df.user_ref.str.contains(init_str)]\n",
    "# filtered_df.nqg_vote_power.describe()\n",
    "df[df.user_ref.str.contains(init_str)].iloc[0].user_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.iloc[1].vote_power_matrix['GAD27OJXIGYJ3LMZ462G6OZ22P5ICENV7TAMMF2DVPR3NYYX2SHIVVZ6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the neuron power tensor to render sim_df quickly\n",
    "neuron_power_tensor_df = sim_df[['neuron_power_tensor', 'label']]\n",
    "sim_df.drop(columns=['neuron_power_tensor'], inplace=True)\n",
    "\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to process and visualize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Voting Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "project_voting_summary(df, round_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Engagement Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "user_engagement_overview(df, round_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.vote_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vote_summary=df.groupby('user_ref').vote_type.value_counts().unstack().fillna(0).astype(int)\n",
    "user_vote_summary\n",
    "# how many users have 0 in delegate\n",
    "user_vote_summary[user_vote_summary['Delegate']!=0].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trust Network Analysis\n",
    "- Visualization of trust relationships and their impact on voting results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trust_network_analysis(sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Cross Comparision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminology:\n",
    "- Standard Voting: This refers to a voting mechanism wherein each participant possesses equal voting power, and the process does not involve Quorum Delegation.\n",
    "- NQG: An acronym for Neural Quorum Governance, a system in which voting weight is determined through a combination of factors such as Trust, Expertise, and Voting History Neurons, in addition to the inclusion of Quorum Delegation.\n",
    "- NG w/o QD: Stands for Neural Governance without Quorum Delegation. In this framework, voting weight is assigned based on Trust, Expertise, and Voting History Neurons; however, it excludes the aspect of Quorum Delegation.\n",
    "- QD w/o NG: Denotes Quorum Delegation without Neural Governance. Under this system, each voter retains an equal vote, but the process allows for the delegation of votes through Quorum Delegation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_map = {\n",
    "    'backtesting': 'NQG',\n",
    "    'no_QD': 'NG w/o QD',\n",
    "    'no_NG': 'QD w/o NG',\n",
    "    'no_NQG': '1 person, 1 vote'}\n",
    "\n",
    "(_, counterfact_df, full_df, ranked_full_df) = get_results_counterfact_full_ranked_dfs(\n",
    "    df, sim_df, scenario_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "counterfactual_heatmap_1(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "counterfactual_heatmap2(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(full_df.reset_index().sort_values('result', ascending=False), x='index', y='result', labels={'result': 'Power', 'index': 'Submission'}).update_layout(height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_heatmap_3(ranked_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_heatmap_3(ranked_full_df[['result', '1 person, 1 vote']].sort_values('result'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_heatmap_3(ranked_full_df[['NQG', 'NG w/o QD']].sort_values('NQG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron Power Tensor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_power_tensor = neuron_power_tensor_df[neuron_power_tensor_df['label']=='backtesting']\n",
    "neuron_power_tensor=neuron_power_tensor['neuron_power_tensor'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_power_tensor.mean(dim='user').mean(dim='project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_power_tensor = neuron_power_tensor_df[neuron_power_tensor_df['label']=='backtesting']\n",
    "neuron_power_tensor=neuron_power_tensor['neuron_power_tensor'].values[1]\n",
    "\n",
    "neuron_power_tensor_neuron0_layer1=neuron_power_tensor.sel(layer=1,neuron=0)/neuron_power_tensor.sel(layer=0).sum(dim='neuron') \n",
    "\n",
    "# Replace NaN values with 0\n",
    "neuron_power_tensor_neuron0_layer1 = neuron_power_tensor_neuron0_layer1.fillna(0)\n",
    "# Replace inf values with 0\n",
    "neuron_power_tensor_neuron0_layer1 = neuron_power_tensor_neuron0_layer1.where(np.isfinite(neuron_power_tensor_neuron0_layer1), 0)\n",
    "\n",
    "neuron_power_tensor.loc[dict(neuron=0, layer=1)] = neuron_power_tensor_neuron0_layer1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vote_decision_matrix=pd.DataFrame(sim_df['vote_decision_matrix'][1])\n",
    "\n",
    "vote_tensor = xr.DataArray(vote_decision_matrix, dims=['project', 'user'])\n",
    "\n",
    "# Ensure matching coordinates (This step is crucial for correct broadcasting and multiplication)\n",
    "vote_tensor = vote_tensor.assign_coords(project=neuron_power_tensor.project.values, user=neuron_power_tensor.user.values)\n",
    "\n",
    "# Broadcast 'vote_tensor' across the 'layer' and 'neuron' dimensions\n",
    "vote_tensor = vote_tensor.expand_dims({'layer': neuron_power_tensor.layer, 'neuron': neuron_power_tensor.neuron}, axis=[-2, -1])\n",
    "\n",
    "# Now multiply\n",
    "resulting_tensor = neuron_power_tensor * vote_tensor\n",
    "\n",
    "\n",
    "# Compute the mean across users as you might want to see the overall trend across projects\n",
    "mean_power = resulting_tensor.mean(dim='user')\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df_mean_power = mean_power.to_dataframe(name='power').reset_index()\n",
    "\n",
    "# Explicitly convert 'layer' and 'neuron' to string if they are not already\n",
    "df_mean_power['layer'] = df_mean_power['layer'].astype(str)\n",
    "df_mean_power['neuron'] = df_mean_power['neuron'].astype(str)\n",
    "\n",
    "# Create a new column that combines 'layer' and 'neuron' for column labels\n",
    "df_mean_power['layer_neuron'] = df_mean_power['layer'] + '_' + df_mean_power['neuron']\n",
    "\n",
    "# drop 1_1\n",
    "df_mean_power = df_mean_power[df_mean_power['layer_neuron'] != '1_1']\n",
    "\n",
    "# rename the column 0_0 to Trust, 0_1 to Reputation, 1_0 to PastHistory\n",
    "df_mean_power['layer_neuron'] = df_mean_power['layer_neuron'].replace({'0_0': 'Trust', '0_1': 'Reputation', '1_0': 'PastHistory'})\n",
    "\n",
    "# Pivot the DataFrame to get 'project' on rows and 'layer_neuron' on columns\n",
    "heatmap_data_power_submissions = df_mean_power.pivot_table(index='project', columns='layer_neuron', values='power')\n",
    "\n",
    "# column reorder to trust, reputation, past history\n",
    "heatmap_data_power_submissions = heatmap_data_power_submissions[['Trust', 'Reputation', 'PastHistory']]\n",
    "\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data_power_submissions, annot=True, cmap='viridis', fmt=\".2f\")\n",
    "plt.title('Mean Power by Project, Layer, and Neuron')\n",
    "plt.ylabel('Project')\n",
    "plt.xlabel('Layer and Neuron')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum across users as you might want to see the overall trend across projects\n",
    "df_sum_power = resulting_tensor.sum(dim='user')\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df_sum_power = df_sum_power.to_dataframe(name='power').reset_index()\n",
    "\n",
    "# Explicitly convert 'layer' and 'neuron' to string if they are not already\n",
    "df_sum_power['layer'] = df_sum_power['layer'].astype(str)\n",
    "df_sum_power['neuron'] = df_sum_power['neuron'].astype(str)\n",
    "\n",
    "# Create a new column that combines 'layer' and 'neuron' for column labels\n",
    "df_sum_power['layer_neuron'] = df_sum_power['layer'] + '_' + df_sum_power['neuron']\n",
    "\n",
    "# drop 1_1\n",
    "df_sum_power = df_sum_power[df_sum_power['layer_neuron'] != '1_1']\n",
    "\n",
    "# rename the column 0_0 to Trust, 0_1 to Reputation, 1_0 to PastHistory\n",
    "df_sum_power['layer_neuron'] = df_sum_power['layer_neuron'].replace({'0_0': 'Trust', '0_1': 'Reputation', '1_0': 'PastHistory'})\n",
    "\n",
    "# Pivot the DataFrame to get 'project' on rows and 'layer_neuron' on columns\n",
    "heatmap_data_sum_power_submissions = df_sum_power.pivot_table(index='project', columns='layer_neuron', values='power')\n",
    "\n",
    "# column reorder to trust, reputation, past history\n",
    "\n",
    "heatmap_data_sum_power_submissions = heatmap_data_sum_power_submissions[['Trust', 'Reputation', 'PastHistory']]\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data_sum_power_submissions, annot=True, cmap='viridis', fmt=\".2f\")\n",
    "plt.title('Sum Power by Project, Layer, and Neuron')\n",
    "plt.ylabel('Project')\n",
    "plt.xlabel('Layer and Neuron')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_power_tensor = neuron_power_tensor_df[neuron_power_tensor_df['label']=='backtesting']\n",
    "# neuron_power_tensor=neuron_power_tensor['neuron_power_tensor'].values[1]\n",
    "\n",
    "\n",
    "vote_decision_matrix=pd.DataFrame(sim_df['vote_decision_matrix'][1])\n",
    "\n",
    "vote_tensor = xr.DataArray(vote_decision_matrix, dims=['project', 'user'])\n",
    "\n",
    "# Ensure matching coordinates (This step is crucial for correct broadcasting and multiplication)\n",
    "vote_tensor = vote_tensor.assign_coords(project=neuron_power_tensor.project.values, user=neuron_power_tensor.user.values)\n",
    "\n",
    "# Broadcast 'vote_tensor' across the 'layer' and 'neuron' dimensions\n",
    "vote_tensor = vote_tensor.expand_dims({'layer': neuron_power_tensor.layer, 'neuron': neuron_power_tensor.neuron}, axis=[-2, -1])\n",
    "\n",
    "# Now multiply\n",
    "resulting_tensor = neuron_power_tensor * vote_tensor\n",
    "\n",
    "# Select layers\n",
    "layer1 = resulting_tensor.sel(layer=0)\n",
    "layer2 = resulting_tensor.sel(layer=1)\n",
    "\n",
    "# Sum across neurons in layer1\n",
    "layer1_sum = layer1.sum(dim='neuron')\n",
    "\n",
    "# Product across neurons in layer2\n",
    "layer2_prod = layer2.prod(dim='neuron')\n",
    "\n",
    "# Calculate final power\n",
    "final_power = abs(layer2_prod) * abs(layer1_sum) * (layer2_prod / abs(layer2_prod))\n",
    "final_power=final_power.drop_vars('layer')\n",
    "\n",
    "# Step 2: Adjusted Calculations\n",
    "# NQG_wo_L1_trust_score: Assume layer1 neuron1 is 0\n",
    "layer1_wo_neuron1 = layer1.copy()\n",
    "layer1_wo_neuron1.loc[dict(neuron=0)] = 0  # Set neuron1 to 0\n",
    "NQG_wo_L1_trust_score = (layer1_wo_neuron1.sum(dim='neuron')) * (layer2.prod(dim='neuron'))\n",
    "\n",
    "# NQG_wo_L1_reputation_score: Assume layer1 neuron2 is 0\n",
    "layer1_wo_neuron2 = layer1.copy()\n",
    "layer1_wo_neuron2.loc[dict(neuron=1)] = 0  # Set neuron2 to 0\n",
    "NQG_wo_L1_reputation_score = (layer1_wo_neuron2.sum(dim='neuron')) * (layer2.prod(dim='neuron'))\n",
    "\n",
    "# NQG_wo_L2_past_round: Assume layer2 neuron1 is 1\n",
    "layer2_wo_neuron1 = layer2.copy()\n",
    "layer2_wo_neuron1.loc[dict(neuron=0)] = 1  # Set neuron1 to 1\n",
    "NQG_wo_L2_past_round = (layer1.sum(dim='neuron')) * (layer2_wo_neuron1.prod(dim='neuron'))\n",
    "\n",
    "# Convert these xarray operations into a new DataArray or Dataset\n",
    "metrics = xr.Dataset({\n",
    "    'NQG': final_power,\n",
    "    'NQG_wo_L1_trust_score': NQG_wo_L1_trust_score,\n",
    "    'NQG_wo_L1_reputation_score': NQG_wo_L1_reputation_score,\n",
    "    'NQG_wo_L2_past_round': NQG_wo_L2_past_round\n",
    "})\n",
    "\n",
    "# Aggregate by user (summing over projects for simplicity, adjust as needed)\n",
    "final_metrics = metrics.sum(dim='user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sim_df['per_project_voting'][1]) - final_metrics.to_dataframe()['NQG']\n",
    "# there is some difference of 0.1 and 0.2 for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics.to_dataframe()['NQG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_metrics = final_metrics.to_dataframe().reset_index().sort_values('NQG', ascending=False)\n",
    "\n",
    "ranked_df = ranked_metrics.set_index('project').rank(method='min', ascending=False)\n",
    "\n",
    "\n",
    "ranked_df = ranked_df.reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(ranked_df.set_index('project').astype(float), annot=True, cmap='viridis', fmt=\".2f\")\n",
    "plt.title('Heatmap of Neuron Power Ranks by Projects')\n",
    "plt.xlabel('Neuron counterfactuals')\n",
    "plt.ylabel('Projects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'ranked_df' is already loaded with your data and 'Project' is set as index.\n",
    "# If not, use the following to set it:\n",
    "ranked_df = ranked_df.set_index('project')\n",
    "\n",
    "# Sample data to illustrate\n",
    "\n",
    "\n",
    "# Calculate the rank differences\n",
    "rank_changes = ranked_df.subtract(ranked_df['NQG'], axis=0)\n",
    "\n",
    "# Calculate absolute rank changes for identifying large movements\n",
    "rank_changes_abs = rank_changes.abs()\n",
    "\n",
    "# Maximum rank change for each project\n",
    "ranked_df['Max_Rank_Change'] = rank_changes_abs.max(axis=1)\n",
    "\n",
    "# Projects with the highest difference in ranks\n",
    "max_change_value = ranked_df['Max_Rank_Change'].max()\n",
    "projects_high_change = ranked_df[ranked_df['Max_Rank_Change'] == max_change_value]\n",
    "\n",
    "# Projects with unchanged ranks across all conditions\n",
    "unchanged_ranks = ranked_df[ranked_df['Max_Rank_Change'] == 0]\n",
    "\n",
    "# Descriptive statistics\n",
    "rank_descriptive_stats = rank_changes_abs.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Projects with Highest Rank Change:\")\n",
    "projects_high_change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nProjects with Unchanged Ranks:\")\n",
    "unchanged_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDescriptive Statistics of Rank Changes:\")\n",
    "rank_descriptive_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
